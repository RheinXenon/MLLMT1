# Lingshu-7B å¤§æ¨¡å‹ä¸‹è½½ä¸è¿è¡Œè®¡åˆ’

## ä¸€ã€ç³»ç»Ÿè¦æ±‚æ£€æŸ¥

### ç¡¬ä»¶è¦æ±‚
- **GPU**: æ¨è NVIDIA GPUï¼Œæ˜¾å­˜è‡³å°‘ 16GBï¼ˆæ¨è 24GB+ï¼‰
  - å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬ï¼ˆ4-bit/8-bitï¼‰
- **å†…å­˜**: è‡³å°‘ 32GB RAM
- **å­˜å‚¨ç©ºé—´**: è‡³å°‘ 20GB å¯ç”¨ç©ºé—´
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11ï¼ˆæ‚¨å½“å‰ç³»ç»Ÿï¼šWindows 10ï¼‰

### è½¯ä»¶è¦æ±‚
- Python 3.8-3.11ï¼ˆæ¨è 3.10ï¼‰
- CUDA 11.8 æˆ– 12.xï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
- Gitï¼ˆç”¨äºå…‹éš†ä»“åº“ï¼‰

---

## äºŒã€ç¯å¢ƒå‡†å¤‡æ­¥éª¤

### æ­¥éª¤ 1: æ£€æŸ¥å¹¶å®‰è£… Python
```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œè¯·ä»å®˜ç½‘ä¸‹è½½ï¼šhttps://www.python.org/downloads/
```

### æ­¥éª¤ 2: æ£€æŸ¥ NVIDIA GPU å’Œ CUDA
```bash
# æ£€æŸ¥ GPU
nvidia-smi

# å¦‚æœæ²¡æœ‰ CUDAï¼Œè¯·ä» NVIDIA å®˜ç½‘ä¸‹è½½ï¼š
# https://developer.nvidia.com/cuda-downloads
```

### æ­¥éª¤ 3: åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ
```bash
# åœ¨é¡¹ç›®ç›®å½•ä¸‹åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆWindows PowerShellï¼‰
.\venv\Scripts\Activate.ps1

# æˆ–ä½¿ç”¨ cmd
.\venv\Scripts\activate.bat
```

### æ­¥éª¤ 4: å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…
```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£… PyTorchï¼ˆCUDA 11.8 ç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£… Transformers å’Œå…¶ä»–ä¾èµ–
pip install transformers accelerate sentencepiece protobuf
pip install bitsandbytes  # ç”¨äºé‡åŒ–åŠ è½½ï¼ˆå¯é€‰ï¼‰

# å®‰è£… Hugging Face CLI
pip install huggingface-hub
```

---

## ä¸‰ã€æ¨¡å‹ä¸‹è½½æ–¹æ¡ˆ

### æ–¹æ¡ˆ A: ä½¿ç”¨ Hugging Face Hubï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹**: è‡ªåŠ¨ç®¡ç†ã€æ”¯æŒæ–­ç‚¹ç»­ä¼ 
**ç¼ºç‚¹**: éœ€è¦ç¨³å®šç½‘ç»œè¿æ¥

```python
from huggingface_hub import snapshot_download

# ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
model_path = snapshot_download(
    repo_id="lingshu-medical-mllm/Lingshu-7B",
    cache_dir="./models",
    resume_download=True  # æ”¯æŒæ–­ç‚¹ç»­ä¼ 
)
print(f"æ¨¡å‹ä¸‹è½½å®Œæˆï¼Œè·¯å¾„ï¼š{model_path}")
```

### æ–¹æ¡ˆ B: ä½¿ç”¨ Git LFS å…‹éš†

```bash
# å®‰è£… Git LFS
git lfs install

# å…‹éš†ä»“åº“ï¼ˆå®Œæ•´ä¸‹è½½ï¼‰
git clone https://huggingface.co/lingshu-medical-mllm/Lingshu-7B

# æˆ–åªä¸‹è½½ç‰¹å®šæ–‡ä»¶
GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/lingshu-medical-mllm/Lingshu-7B
cd Lingshu-7B
git lfs pull --include="*.bin,*.safetensors"  # åªä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶
```

### æ–¹æ¡ˆ C: æ‰‹åŠ¨ä¸‹è½½ï¼ˆç½‘ç»œä¸ç¨³å®šæ—¶ï¼‰

è®¿é—®ï¼šhttps://huggingface.co/lingshu-medical-mllm/Lingshu-7B/tree/main

æ‰‹åŠ¨ä¸‹è½½ä»¥ä¸‹å…³é”®æ–‡ä»¶ï¼š
- `config.json`
- `tokenizer.json` / `tokenizer_config.json`
- `pytorch_model.bin` æˆ– `*.safetensors` æ–‡ä»¶
- `generation_config.json`

---

## å››ã€æ¨¡å‹åŠ è½½ä¸è¿è¡Œ

### æ–¹å¼ 1: æ ‡å‡†åŠ è½½ï¼ˆéœ€è¦è¶³å¤Ÿæ˜¾å­˜ï¼‰

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model_path = "lingshu-medical-mllm/Lingshu-7B"  # æˆ–æœ¬åœ°è·¯å¾„
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True
)

# æµ‹è¯•æ¨ç†
prompt = "è¯·ä»‹ç»ä¸€ä¸‹é«˜è¡€å‹çš„ç—‡çŠ¶å’Œæ²»ç–—æ–¹æ³•ã€‚"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_length=512, temperature=0.7)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

### æ–¹å¼ 2: é‡åŒ–åŠ è½½ï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼Œæ¨èï¼‰

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch

# 4-bit é‡åŒ–é…ç½®
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
)

model_path = "lingshu-medical-mllm/Lingshu-7B"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=quantization_config,
    device_map="auto",
    trust_remote_code=True
)

# æµ‹è¯•æ¨ç†ï¼ˆåŒä¸Šï¼‰
```

### æ–¹å¼ 3: CPU åŠ è½½ï¼ˆæ—  GPU æ—¶ï¼Œé€Ÿåº¦è¾ƒæ…¢ï¼‰

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = "lingshu-medical-mllm/Lingshu-7B"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float32,
    device_map="cpu",
    trust_remote_code=True
)
```

---

## äº”ã€æ¨èæ‰§è¡Œæµç¨‹

### ç¬¬ä¸€é˜¶æ®µï¼šç¯å¢ƒå‡†å¤‡ï¼ˆé¢„è®¡ 30-60 åˆ†é’Ÿï¼‰
1. âœ… æ£€æŸ¥ Python ç‰ˆæœ¬
2. âœ… æ£€æŸ¥ GPU å’Œ CUDA
3. âœ… åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
4. âœ… å®‰è£…ä¾èµ–åŒ…

### ç¬¬äºŒé˜¶æ®µï¼šæ¨¡å‹ä¸‹è½½ï¼ˆé¢„è®¡ 1-3 å°æ—¶ï¼Œå–å†³äºç½‘é€Ÿï¼‰
1. âœ… é€‰æ‹©ä¸‹è½½æ–¹æ¡ˆï¼ˆæ¨èæ–¹æ¡ˆ Aï¼‰
2. âœ… æ‰§è¡Œä¸‹è½½è„šæœ¬
3. âœ… éªŒè¯æ–‡ä»¶å®Œæ•´æ€§

### ç¬¬ä¸‰é˜¶æ®µï¼šæµ‹è¯•è¿è¡Œï¼ˆé¢„è®¡ 10-20 åˆ†é’Ÿï¼‰
1. âœ… ç¼–å†™æµ‹è¯•è„šæœ¬
2. âœ… åŠ è½½æ¨¡å‹ï¼ˆæ ¹æ®ç¡¬ä»¶é€‰æ‹©åŠ è½½æ–¹å¼ï¼‰
3. âœ… æ‰§è¡Œæ¨ç†æµ‹è¯•
4. âœ… éªŒè¯è¾“å‡ºç»“æœ

---

## å…­ã€å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: ä¸‹è½½é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨å›½å†…é•œåƒç«™ï¼ˆå¦‚æœæœ‰ï¼‰
- ä½¿ç”¨ä»£ç†åŠ é€Ÿ
- å°è¯•åœ¨ç½‘ç»œç©ºé—²æ—¶æ®µä¸‹è½½
- ä½¿ç”¨æ–¹æ¡ˆ C æ‰‹åŠ¨åˆ†æ‰¹ä¸‹è½½

### Q2: æ˜¾å­˜ä¸è¶³æŠ¥é”™ï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**:
- ä½¿ç”¨ 4-bit æˆ– 8-bit é‡åŒ–åŠ è½½
- å‡å°‘ batch size
- ä½¿ç”¨ CPU æ¨ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰
- è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹å˜ä½“

### Q3: CUDA ç‰ˆæœ¬ä¸åŒ¹é…ï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¸è½½ç°æœ‰ PyTorch
pip uninstall torch torchvision torchaudio

# å®‰è£…å¯¹åº” CUDA ç‰ˆæœ¬çš„ PyTorch
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Q4: ç¼ºå°‘æŸäº›ä¾èµ–åŒ…ï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**:
```bash
pip install einops timm pillow
```

---

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨ Flash Attention**: å®‰è£… `flash-attn` å¯ä»¥æå‡æ¨ç†é€Ÿåº¦
2. **ä½¿ç”¨ vLLM**: éƒ¨ç½²é«˜æ€§èƒ½æ¨ç†æœåŠ¡
3. **æ‰¹é‡æ¨ç†**: åŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚ä»¥æé«˜ååé‡
4. **æ¨¡å‹é‡åŒ–**: åœ¨ç²¾åº¦å¯æ¥å—çš„æƒ…å†µä¸‹ä½¿ç”¨é‡åŒ–æ¨¡å‹

---

## å…«ã€åç»­æ­¥éª¤

å®ŒæˆåŸºç¡€æµ‹è¯•åï¼Œæ‚¨å¯ä»¥ï¼š
- ğŸ”§ æ­å»º Web ç•Œé¢ï¼ˆä½¿ç”¨ Gradio/Streamlitï¼‰
- ğŸ”§ å¼€å‘ API æœåŠ¡ï¼ˆä½¿ç”¨ FastAPIï¼‰
- ğŸ”§ å¾®è°ƒæ¨¡å‹ä»¥é€‚åº”ç‰¹å®šåœºæ™¯
- ğŸ”§ é›†æˆåˆ°æ‚¨çš„åº”ç”¨ç³»ç»Ÿä¸­

---

## å‚è€ƒèµ„æº

- **æ¨¡å‹ä¸»é¡µ**: https://huggingface.co/lingshu-medical-mllm/Lingshu-7B
- **Transformers æ–‡æ¡£**: https://huggingface.co/docs/transformers
- **PyTorch å®˜ç½‘**: https://pytorch.org/
- **CUDA ä¸‹è½½**: https://developer.nvidia.com/cuda-downloads

