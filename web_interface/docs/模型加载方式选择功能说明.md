# 模型加载方式选择功能说明

## 📋 功能概述

在设置页面新增了模型加载方式选择功能，用户可以根据自己的硬件配置选择最合适的模型加载方式。

## ✨ 新增功能

### 1. 四种加载方式

- **4-bit 量化** (默认)
  - 显存占用最小
  - 适合 8GB 显存显卡
  - 推荐日常使用

- **8-bit 量化**
  - 显存占用适中
  - 推荐 16GB 显存显卡
  - 性能与显存的平衡选择

- **标准模式**
  - 原始精度，效果最佳
  - 需要 24GB+ 显存
  - 适合高端显卡

- **CPU模式**
  - 使用CPU运行
  - 无需显卡
  - 速度较慢但兼容性好

### 2. 页面滚动修复

- 修复了设置页面内容超出下边界无法滚动的问题
- 添加了 `overflow-y: auto` 属性到设置内容区域
- 所有设置项现在都可以正常访问

## 🔧 技术实现

### 后端修改 (app.py)

1. **API 接口增强**
   ```python
   @app.route('/api/load_model', methods=['POST'])
   def load_model():
       # 接收量化模式参数
       data = request.get_json() if request.is_json else {}
       quantization = data.get('quantization', config.DEFAULT_QUANTIZATION)
       
       # 验证量化模式
       valid_modes = ['4bit', '8bit', 'standard', 'cpu']
       if quantization not in valid_modes:
           return jsonify({"success": False, "error": "无效的量化模式"}), 400
   ```

2. **状态接口改进**
   - 返回实际加载的量化模式（而非配置文件中的默认值）

### 前端修改

1. **settings.html**
   - 添加量化模式选择下拉框
   - 显示详细的模式说明

2. **settings.js**
   - 保存和加载用户选择的量化模式
   - 加载模型时传递选择的模式
   - 显示友好的加载提示信息

3. **api.js**
   - `loadModel()` 方法接受 `quantization` 参数

4. **style.css**
   - 添加下拉选择框样式
   - 修复页面滚动问题

## 💾 设置持久化

用户选择的量化模式会保存到浏览器的 `localStorage`，下次访问时自动恢复选择。

存储结构：
```javascript
{
  "temperature": 0.7,
  "maxTokens": 512,
  "quantization": "4bit"  // 新增
}
```

## 🎯 使用方法

1. 访问设置页面
2. 在"模型控制"面板中选择加载方式
3. 点击"加载模型"按钮
4. 系统会使用选择的方式加载模型

## ⚠️ 注意事项

1. **显存要求**：请根据显卡显存容量选择合适的加载方式
2. **切换模式**：需要先卸载当前模型，再选择新模式重新加载
3. **CPU模式**：虽然无需显卡，但推理速度会明显下降
4. **首次加载**：无论哪种模式，首次加载都需要几分钟时间

## 📊 显存占用参考

| 加载方式 | 显存占用 | 推荐显卡 |
|---------|---------|---------|
| 4-bit   | ~4-6 GB | RTX 3060 8GB+ |
| 8-bit   | ~8-10 GB | RTX 3080 10GB+ |
| 标准模式 | ~14-16 GB | RTX 4090 24GB+ |
| CPU模式 | ~0 GB (使用内存) | 无显卡 |

## 🔄 版本历史

- **v1.0** (2025-11-03)
  - 初始实现
  - 支持 4 种加载方式
  - 修复页面滚动问题

